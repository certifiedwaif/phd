\documentclass{beamer}

\usetheme{Warsaw}
\usepackage{graphicx}
\usepackage{ulem}
\usepackage{tikz}
\input{include.tex}
\input{Definitions.tex}

\usefonttheme{serif}

\title{Progress update}
\author{Mark Greenaway}

\mode<presentation>
{ \usetheme{boxes} }

\begin{document}
\begin{frame}
\titlepage
\end{frame}

\begin{frame}{Mean field updates and variational lower bound \ldots nearly done}
\begin{itemize}
\item The mean field updates are done
\item These turn out to be really nice, everything is in terms of $\tau_g = \E [g^{-1}]$
			and fixed constants $n$, $\|\vy\|^2$ and $R^2$
\item We already have parallel code	to calculate $R^2$
\item This allows us to do Variational Bayes by optimising one variational parameter. So we can do them all 
			at once!
\item Variational lower bound in progress -- just looking for errors
\item I'm writing, \textbf{then} coding -- I have a thesis to produce
\item John is admonishing me on my writing style, which is probably for the best
\item Structured Variational Bayes
\end{itemize}
\end{frame}

\begin{frame}{Model selection algorithms. Maybe brute force isn't so bad after all}
\begin{itemize}
\item We're performing all $2^p$ model fits, so our algorithm is $\BigO(2^p n p^2)$ - which is to say,
			exponential time complexity
\item That sounded terrible to me. So what are the alternatives?
\item Branch and bound, as implemented in \texttt{leaps}. Worst case is still $\BigO(2^p n p^2)$. Pushing it
			to do $p = 30$
\item Mixed Integer Optimisation - still NP hard
\item Step selection uses a greedy algorithm -- but this doesn't select optimal models because there is no
			guaranteed ``safe move''. So you get stuck in local optima
\item No silver bullet -- to my knowledge there is \textbf{no} polynomial time algorithm known which
			will perform this task
\item So I'm going to stop worrying about it for now
\end{itemize}
\end{frame}

\begin{frame}{The End of Moore's Law}
\begin{itemize}
\item For a long time, computers have been getting faster and faster, the famous
			Moore's Law -- ``the number of components per integrated circuit doubled roughly every 18 months'' -- 
			has held from 1965 to just about now
\item This used to be great. If something was too slow, you'd just wait for the next fastest CPU to come out
			and just re-run it
\item This is now over, as the physical limits of silicon are being reached -- particularly the power wall. 
			The semiconductor industry has abandoned Moore's Law as a target
\item So now what?!?
\item No, really, I'm asking \textbf{you}
\end{itemize}
\end{frame}

\begin{frame}{Multi-core, GPUs, distributed computing}
\begin{itemize}
\item Multi-core, GPUs and distributed computing are partial answers. But these don't help for every
			algorithm
\item R was developed in a single-core world, with a single-core design. You might be waiting a long time for
			these things to be supported fully in R
\item I'm not waiting. I'm using languages that support these things which can be called by R. Multi-core, 
			distributed computing, GPUs -- bring it on
\item About a quarter of our research servers are currently down due to air conditioner failure. Dr
			Mathas is aware
\item HPC typically has 15 to 20 nodes free at any one time -- 24 cores each
\item GPU nodes are also available -- no need to wait for hardware
\item OpenMP supported on GPUs in Clang already, and in will be in GCC in 6.x. Don't need to change much code
\end{itemize}
\end{frame}

\end{document}