The problem of model selection in the context of linear models is well-studied. Zellner (1986)  first
introduced the idea of a prior on the regression coefficients for a model using the hyperprior $g$ to control
Bayesian model averaging. An alternative choice of prior on the regression coefficients for a model with
computational advantages was later proposed by Maruyama & George (2011), using the eigenvalue decomposition of
the cross-product of the covariate matrix for a model.

The hyperprior on $g$ must be carefully chosen when performing model selection to ensure model selection
consistency and avoid paradoxes such as Bartlett's  Paradox and the Information Paradox. Liang et al. (2008)
showed that while a fixed choice of $g$ falls prey to these paradoxes, a mixture of $g$-priors avoids them.

We consider linear models with a special case of the prior structure proposed in Maruyama & George (2011) and
perform numerical analyses of the resulting parameter posterior distributions. To this end we derive several
approaches including Monte Carlo sampling schemes. We derive new exact expressions for these posterior
parameter distributions in terms of special functions and distributions where possible, and derive exact
expression for the first and second posterior moments for the other parameters. We provide convenient
asymptotic approximations of parameter posterior distributions where exact expressions could not be obtained.
We show that, under a particular asymptotic setting, model averaging using the chosen prior is asymptotically
equivalent to model averaging under the Bayesian Information Criterion (BIC).

Implementation issues of Bayesian model averaging under the proposed prior structure are also discussed and R
software is made available for this purpose. Our methodology is illustrated on several datasets taken from the
StatLib library.
